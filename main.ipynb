{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f82a8cc-7b02-48d7-a783-6e89bccff8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T09:52:03.666001Z",
     "iopub.status.busy": "2024-05-23T09:52:03.664553Z",
     "iopub.status.idle": "2024-05-23T09:52:05.678380Z",
     "shell.execute_reply": "2024-05-23T09:52:05.677351Z",
     "shell.execute_reply.started": "2024-05-23T09:52:03.665915Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ensemble_model.preprocesser as preprocesser \n",
    "import ensemble_model.ensemble_model as em \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer, RobertaModel, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581b2000-7c82-4109-9761-1f0ea8e3f727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T12:56:02.901676Z",
     "iopub.status.busy": "2024-05-22T12:56:02.901414Z",
     "iopub.status.idle": "2024-05-22T12:56:06.307119Z",
     "shell.execute_reply": "2024-05-22T12:56:06.306011Z",
     "shell.execute_reply.started": "2024-05-22T12:56:02.901657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1332/3675444814.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({\"label\": label2id})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(r'/root/autodl-tmp/dataset.csv', index_col=0, encoding='utf_8_sig')\n",
    "df.fillna('', inplace=True)\n",
    "label2id={'negative':0,'positive':1}\n",
    "df = df.replace({\"label\": label2id})\n",
    "df\n",
    "df['command'] = df['diff'].apply(lambda x : ' '.join(x.split('@@')[:2]))\n",
    "df\n",
    "df_dataset = []\n",
    "for index, row in df.iterrows():\n",
    "  df_dataset.append([row['message'],row['command'],row['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b77e6e8-8d9d-45f3-be04-94a8b7499213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T12:56:06.308195Z",
     "iopub.status.busy": "2024-05-22T12:56:06.308012Z",
     "iopub.status.idle": "2024-05-22T12:56:06.900178Z",
     "shell.execute_reply": "2024-05-22T12:56:06.899123Z",
     "shell.execute_reply.started": "2024-05-22T12:56:06.308175Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Load BERT and CodeBERT models and tokenizers\n",
    "bert_model = BertModel.from_pretrained('/root/autodl-tmp/models/bert-base-cased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('/root/autodl-tmp/models/bert-base-cased')\n",
    "\n",
    "codebert_model = RobertaModel.from_pretrained('/root/autodl-tmp/models/codebert-base')\n",
    "codebert_tokenizer = RobertaTokenizer.from_pretrained('/root/autodl-tmp/models/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1549be02-6f6b-41e5-bd04-d3e164061eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T12:56:06.901316Z",
     "iopub.status.busy": "2024-05-22T12:56:06.901133Z",
     "iopub.status.idle": "2024-05-22T13:13:38.574302Z",
     "shell.execute_reply": "2024-05-22T13:13:38.573125Z",
     "shell.execute_reply.started": "2024-05-22T12:56:06.901298Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.38329278773595044\n",
      "Epoch 2/10, Loss: 0.21524139500467895\n",
      "Epoch 3/10, Loss: 0.11586756651115368\n",
      "Epoch 4/10, Loss: 0.06922818381718236\n",
      "Epoch 5/10, Loss: 0.046098551449112034\n",
      "Epoch 6/10, Loss: 0.0346014918456492\n",
      "Epoch 7/10, Loss: 0.03234461589072668\n",
      "Epoch 8/10, Loss: 0.02589775442330885\n",
      "Epoch 9/10, Loss: 0.0260394861467539\n",
      "Epoch 10/10, Loss: 0.02616635528946839\n",
      "Validation Accuracy: 0.9050914483440435\n",
      "Precision: 0.8792207792207792\n",
      "Recall: 0.8724226804123711\n",
      "F1-Score: 0.8758085381630013\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "# preprocesser = preprocesser.SentencePairDataset(train_data, bert_tokenizer, codebert_tokenizer)\n",
    "train_data, val_data = train_test_split(df_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Datasets and DataLoaders\n",
    "train_dataset = preprocesser.SentencePairDataset(train_data, bert_tokenizer, codebert_tokenizer)\n",
    "val_dataset = preprocesser.SentencePairDataset(val_data, bert_tokenizer, codebert_tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = em.CombinedModel(bert_model, codebert_model, bert_tokenizer, codebert_tokenizer)\n",
    "\n",
    "# Train the model\n",
    "model.trainer(train_loader, val_loader,num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de47b49-8d23-4eca-9690-1cff4771159b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
